{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# activations\n",
    "\n",
    "> Deeper understanding of activations in MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp makemore.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from minion.makemore.bigram import stoi, itos\n",
    "from minion.makemore.mlp import build_XY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivations\n",
    "\n",
    "- We want to move to more complex neural networks like RNN, GRU and transformers\n",
    "- Before doing that better to gain deeper understanding of activations and back propogation and their historical context.\n",
    "- While RNN very expressive - universal function approximator algorithms; they are not very easily optimizable from the first order techniques available to us and that we use all the time.\n",
    "- Key to understanding why they don't optimize easily ; is to understand activations and gradient and how they behave during training. Lot of variance in NN architectures that we see are owing to this fact and innovations are around how they have tried to rectify these situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
